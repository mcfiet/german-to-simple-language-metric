\subsection{Fazit und Ausblick}
Die Arbeit zeigt, dass eine datengetriebene Metrik für Leichte Sprache erfolgreich auf synthetischen Paaren trainiert werden kann und dass Transformer-Modelle mit Encoder-Anpassung die beste Balanced Accuracy erreichen. Gleichzeitig bleibt die Pipeline nachvollziehbar und reproduzierbar, sodass sowohl Datenerzeugung als auch Modelltraining systematisch erweitert werden können. Die zusätzlichen Runs auf größeren synthetischen Datensätzen (HTTP/FlensGenGPTOSS sowie 1:5-Varianten mit Oversampling) bestätigen den Trend: Mehr Daten steigern die Testleistung, allerdings wird der Zugewinn durch Klassenbalance und Sampling-Strategie beeinflusst. Die Ergebnisse legen nahe, dass die Metrik als Reward-Funktion oder Bewertungssignal in Übersetzungssystemen einsetzbar ist, sofern eine externe Validierung bestätigt, dass das synthetische Signal auf reale Daten übertragbar ist.

\subsection*{Kritik an der Arbeit}
Die Evaluierung basiert stark auf synthetischen Daten, die zwar kontrolliert und umfangreich sind, aber reale Übersetzungsfehler und stilistische Varianz nur begrenzt abbilden. Die Generalisierung auf manuell alignierte oder annotierte Korpora wurde noch nicht systematisch gemessen. Zudem kann die starke Abhängigkeit von Prompt-Design und Generierungsregeln zu verzerrten Lernsignalen führen.

\subsection*{Learnings}
Die Experimente zeigen, dass die Modelldynamik stark vom Encoder-Training abhängt: Ein eingefrorener Encoder limitiert die Leistung deutlich, während partielle Freigaben und LoRA große Zugewinne bei moderatem Aufwand liefern. Synthetische Daten können als Katalysator dienen, sollten aber früh durch reale Beispiele validiert werden, um Fehlerbilder nicht zu verfestigen.

\subsection*{Ausblick}
Als nächste Schritte sollten die synthetischen Generatoren (einschließlich der HTTP-Variante) konsolidiert und ihre Datenversionen dokumentiert werden. Darauf aufbauend ist eine Validierung auf hand-alignierten und annotierten Datensätzen notwendig, um die Übertragbarkeit zu quantifizieren. Methodisch bietet sich eine kombinierte Metrik an, die semantische Übereinstimmung mit Lesbarkeits- und Regelmerkmalen verbindet. Abschließend kann die Metrik als Reward-Funktion in einer Übersetzungspipeline getestet werden, um den praktischen Nutzen direkt zu evaluieren.
