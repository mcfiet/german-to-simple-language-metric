\subsection{Fazit und Ausblick}
Die Arbeit zeigt, dass eine datengetriebene Metrik für Leichte Sprache erfolgreich auf synthetischen Paaren trainiert werden kann und dass Transformer-Modelle mit Encoder-Anpassung die beste Balanced Accuracy erreichen \parencite{vaswani2017attention}. Gleichzeitig bleibt die Pipeline nachvollziehbar und reproduzierbar, sodass sowohl Datenerzeugung als auch Modelltraining systematisch erweitert werden können. Die zusätzlichen Runs auf größeren synthetischen Datensätzen (HTTP/FlensGenGPTOSS sowie 1:5-Varianten mit Oversampling) bestätigen den Trend: Mehr Daten steigern die Testleistung, allerdings wird der Zugewinn durch Klassenbalance und Sampling-Strategie beeinflusst. Die Ergebnisse legen nahe, dass die Metrik als Reward-Funktion oder Bewertungssignal in Übersetzungssystemen einsetzbar ist, sofern eine externe Validierung bestätigt, dass das synthetische Signal auf reale Daten übertragbar ist.

\subsection*{Kritik an der Arbeit}
Die Evaluierung basiert stark auf synthetischen Daten, die zwar kontrolliert und umfangreich sind, aber reale Übersetzungsfehler und stilistische Varianz nur begrenzt abbilden. Die Generalisierung auf manuell alignierte oder annotierte Korpora wurde noch nicht systematisch gemessen. Zudem kann die starke Abhängigkeit von Prompt-Design und Generierungsregeln zu verzerrten Lernsignalen führen.

\subsection*{Learnings}
Die Experimente zeigen, dass die Modelldynamik stark vom Encoder-Training abhängt: Ein eingefrorener Encoder limitiert die Leistung deutlich, während partielle Freigaben und LoRA große Zugewinne bei moderatem Aufwand liefern \parencite{hu2021lora}. Synthetische Daten können den Prozess beschleunigen, sollten aber früh durch reale Beispiele validiert werden, um Fehlerbilder nicht zu verfestigen. Insgesamt ist das ein sehr guter Schritt, trotzdem war die Zeit für Datensatzerstellung und für den Aufbau der Metrik zu knapp, sodass man trotz der Ergebnisse das Gefühl behält, erst an der Oberfläche gekratzt zu haben. Vielleicht hätte man sich noch mehr auf die Datenerstellung oder auf den Aufbau der Metrik konzentrieren sollen, anstatt zu viele Experimente durchzuführen.

\subsection*{Ausblick}
Als nächste Schritte sollten die synthetischen Generatoren weiter ausgebessert werden um die Qualität der Datensätze zu erhöhen. Darauf aufbauend ist eine Validierung auf hand-alignierten und annotierten Datensätzen notwendig, um die Übertragbarkeit zu testen. Methodisch bietet sich eine kombinierte Metrik an, die semantische Übereinstimmung mit Lesbarkeits- und Regelmerkmalen verbindet. Abschließend kann die Metrik als Reward-Funktion in einer Übersetzungspipeline getestet werden, um den praktischen Nutzen direkt zu evaluieren.
